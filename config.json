{
    "general": {
        "batch_size": 128,
        "epochs": 400,
        "lr": 0.00000991301767144166,
        "loss_fn": "mean_squared_error"
    },

    "architecture": {
        "compile": false,
        "embedding": {
            "embed_dim": 128 
        },
        "transformer_block": {
            "num_blocks": 5,
            "activation": "selu",
            "ff_dim": 128,
            "num_heads": 21,
            "dr1": 0.12717945391278226,
            "dr2": 0.12717945391278226,
            "drop_mha": true
        },
        "regressor_head": {
            "activation": "selu",
            "dr": 0.04990303516069576
        }
    }
}
